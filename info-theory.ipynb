{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.special import xlogy\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "We flip a coin which comes up heads with probability $p$ and tails with probability $1âˆ’p$.\n",
    "\n",
    "1. What is the information entropy of the coin?\n",
    "2. What value of $p$ gives the largest entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_entropy(p: np.ndarray):\n",
    "    return -xlogy(p, p) - xlogy(1-p, 1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=x, y=coin_entropy(x), labels={'x': 'probability', 'y': 'entropy'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Luna and I happen upon a coin.  Upon inspecting the coin, I believe that the coin is fair while Luna thinks heads is twice as likely to come up as tails.\n",
    "\n",
    "We flip the coin 1000 times, and it comes up heads 600 times.\n",
    "Who is more surprised by this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_relative_entropy(p, q):\n",
    "    return -xlogy(p, q/p) - xlogy(1-p, (1-q)/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_me = 1/2\n",
    "q_luna = 2/3\n",
    "p = 600/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_relative_entropy(p, q_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_relative_entropy(p, q_luna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Given the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (.01, .03, .06),\n",
    "        (.09, .77, .04)\n",
    "    ],\n",
    "    columns=['positive', 'negative', 'neutral'],\n",
    "    index=['covid', 'no_covid']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are the covid and sentiment variables independent?\n",
    "2. What are the marginal density functions of covid and sentiment?\n",
    "3. What are the various possible conditional density functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around with mutual information a bit.\n",
    "First, we need an implementation that works on a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(joint_density: pd.DataFrame) -> float:\n",
    "    '''\n",
    "    Input: DataFrame representing the joint density of a pair of random variables\n",
    "    Output: Mutual information of the two random variables\n",
    "    '''\n",
    "    independent_density = pd.DataFrame(\n",
    "        expected_freq(joint_density),\n",
    "        columns=joint_density.columns,\n",
    "        index=joint_density.index\n",
    "    )\n",
    "    return -(joint_density * np.log2(independent_density / joint_density)).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this to compute the mutual information of some random variables that come from text.\n",
    "Let's load in some reddit data (about 10000 posts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('gdrive/My Drive/Colab Notebooks/reddit_calculus.parquet')\n",
    "# df = pd.read_parquet('/Users/paul/data/reddit/reddit_calculus.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll play around with the words and phrases appearing in the text of the posts, so we should start by cleaning it up and tokenizing it.\n",
    "Here is a brutal approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['url'].apply(lambda url: url.split('/')[4].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english', max_features=100)\n",
    "count_matrix = cv.fit_transform(df['text'])\n",
    "count_df = pd.DataFrame(count_matrix.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mutual information for one of the following pairs of variables (or another pair of your choosing!):\n",
    "1. Occurrence of two terms of your choosing\n",
    "2. Occurrence of a term of your choosing in a randomly chosen document\n",
    "3. Occurrence of terms by subreddit\n",
    "\n",
    "What is the intuitive meaning of mutual information in each of these examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whichever example you chose, compute all pointwise mutual information scores and all TF-IDF scores.  Which gives a better notion of relevance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
